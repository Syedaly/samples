import sys
from pyspark.sql import SparkSession
from pyspark.sql.functions import lit

# Initialize Spark Session for AWS Glue
spark = SparkSession.builder \
    .appName("Repartition Iceberg Table") \
    .config("spark.sql.catalog.glue_catalog", "org.apache.iceberg.spark.SparkCatalog") \
    .config("spark.sql.catalog.glue_catalog.catalog-impl", "org.apache.iceberg.aws.glue.GlueCatalog") \
    .config("spark.sql.catalog.glue_catalog.warehouse", "s3://your-warehouse-path/") \
    .config("spark.sql.extensions", "org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions") \
    .getOrCreate()

# Step 1: Read the unpartitioned Iceberg table
unpartitioned_table_path = "s3://your-bucket/unpartitioned-table/"
unpartitioned_df = spark.read.format("iceberg").load(unpartitioned_table_path)

# Step 2: Add a new partition column (Static Year Example)
repartitioned_df = unpartitioned_df.withColumn("year", lit(2024))

# Step 3: Write the data to a new Iceberg table with partitioning
repartitioned_table_path = "s3://your-bucket/repartitioned-table/"
repartitioned_df.write \
    .format("iceberg") \
    .partitionBy("year") \
    .save(repartitioned_table_path)

# Stop the Spark session
spark.stop()
