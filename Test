## Lambda:
import json
import boto3
import uuid
from datetime import datetime
import os

def lambda_handler(event, context):
    stepfunctions = boto3.client('stepfunctions')
    sqs = boto3.client('sqs')
    
    # Configuration - to be set in Env
    STATE_MACHINE_ARN = 'arn:aws:states:us-west-2:420393866958:stateMachine:sap-poc-datalakepredevtest3'
    SNS_TOPIC_ARN = 'arn:aws:sns:us-west-2:420393866958:DeltaFiles-StepFunctionCallback'
    SQS_QUEUE_URL = 'https://sqs.us-west-2.amazonaws.com/420393866958/file-processing.fifo'
    
    print(f"Received event: {json.dumps(event, default=str)}")
    
    # Check if this is an SQS trigger or SNS callback
    if 'Records' in event:
        source = event['Records'][0].get('eventSource', '')
        
        if source == 'aws:sqs':
            return handle_sqs_message(event, stepfunctions, STATE_MACHINE_ARN, SNS_TOPIC_ARN, SQS_QUEUE_URL)
        elif source == 'aws:sns':
            return handle_sns_callback(event, sqs)
    
    return {'statusCode': 400, 'body': 'Unknown event source'}

def handle_sqs_message(event, stepfunctions, state_machine_arn, sns_topic_arn, queue_url):
    """Handle initial SQS message - start Step Function ONLY if none are running"""
    
    for record in event['Records']:
        try:
            # Parse S3 event from SQS
            s3_event = json.loads(record['body'])
            bucket = s3_event['detail']['bucket']['name']  
            key = s3_event['detail']['object']['key']      
            
            print(f"Processing file: s3://{bucket}/{key}")
            print(f"SQS Message ID: {record['messageId']}")
            
            # CHECK: Is any Step Function execution currently running?
            if is_step_function_running(stepfunctions, state_machine_arn):
                print("STEP FUNCTION ALREADY RUNNING - Returning message to queue")
                
                # Return message to queue with delay for sequential processing
                sqs = boto3.client('sqs')
                sqs.change_message_visibility(
                    QueueUrl=queue_url,
                    ReceiptHandle=record['receiptHandle'],
                    VisibilityTimeout=60  # 300 for 5 minutes delay before retry
                )
                
                return {
                    'statusCode': 200, 
                    'body': 'Step Function already running - message returned to queue'
                }
            
            # Generate unique execution name
            timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
            unique_id = str(uuid.uuid4())[:8]
            execution_name = f"process-{timestamp}-{unique_id}"
            
            # Get current date in YYYY-MM-DD format
            current_date = datetime.now().strftime('%Y-%m-%d')
            
            # Step Function input with current date and callback info
            step_input = {
                'SELECTED_RUN_DATE': current_date,
                'bucket': bucket,
                'key': key,
                'callbackInfo': {
                    'snsTopicArn': sns_topic_arn,
                    'sqsQueueUrl': queue_url,
                    'receiptHandle': record['receiptHandle'],
                    'messageId': record['messageId'],
                    'executionName': execution_name
                }
            }
            
            print(f"STARTING STEP FUNCTION")
            print(f"Step Function input: {json.dumps(step_input)}")
            print(f"Using run date: {current_date}")
            
            # Start Step Function
            response = stepfunctions.start_execution(
                stateMachineArn=state_machine_arn,
                name=execution_name,
                input=json.dumps(step_input)
            )
            
            print(f"Started Step Function: {response['executionArn']}")
            
        except Exception as e:
            print(f"Error starting Step Function: {str(e)}")
            print(f"Record content: {json.dumps(record, default=str)}")
            raise e
    
    return {'statusCode': 200, 'body': 'Step Function started successfully'}

def is_step_function_running(stepfunctions, state_machine_arn):
    """Check if any executions of the Step Function are currently running"""
    
    try:
        # List running executions
        response = stepfunctions.list_executions(
            stateMachineArn=state_machine_arn,
            statusFilter='RUNNING',
            maxResults=1  # We only need to know if ANY are running
        )
        
        running_executions = response.get('executions', [])
        
        if running_executions:
            print(f"Found {len(running_executions)} running executions:")
            for execution in running_executions:
                print(f"  - {execution['name']} (started: {execution['startDate']})")
            return True
        else:
            print("No running executions found")
            return False
            
    except Exception as e:
        print(f"Error checking Step Function status: {e}")
        # If we can't check, assume it's safe to proceed
        return False

def handle_sns_callback(event, sqs):
    """Handle SNS callback - manage SQS message"""
    
    for record in event['Records']:
        try:
            # Parse SNS message - handle both string and object formats
            sns_message_raw = record['Sns']['Message']
            
            # Check if message is already parsed or needs parsing
            if isinstance(sns_message_raw, str):
                sns_message = json.loads(sns_message_raw)
            else:
                sns_message = sns_message_raw
            
            status = sns_message.get('status')
            callback_info = sns_message.get('callbackInfo', {})
            
            queue_url = callback_info.get('sqsQueueUrl')
            receipt_handle = callback_info.get('receiptHandle')
            message_id = callback_info.get('messageId')
            
            print(f"Processing SNS callback - Status: {status}, Message ID: {message_id}")
            
            if status == 'SUCCESS':
                # Delete SQS message on success
                sqs.delete_message(
                    QueueUrl=queue_url,
                    ReceiptHandle=receipt_handle
                )
                print(f"SUCCESS: Deleted SQS message {message_id}")
                print("Next message in queue can now be processed")
                
            elif status == 'FAILED':
                # Return message to queue for retry with delay
                sqs.change_message_visibility(
                    QueueUrl=queue_url,
                    ReceiptHandle=receipt_handle,
                    VisibilityTimeout=900  # 15 minutes delay for failed messages
                )
                print(f"FAILED: Message {message_id} will retry in 15 minutes")
                
        except Exception as e:
            print(f"Error handling SNS callback: {str(e)}")
            print(f"SNS record: {json.dumps(record, default=str)}")
            # Don't raise - we don't want SNS to retry
    
    return {'statusCode': 200, 'body': 'SNS callback processed successfully'}


##StepFunctions:

{
  "Comment": "Runs an ETL pipeline to process SAP source data from Raw layer all the way to the Analytics layer",
  "StartAt": "Lambda Invoke run_date_selector",
  "States": {
    "Lambda Invoke run_date_selector": {
      "Type": "Task",
      "Resource": "arn:aws:states:::lambda:invoke",
      "Parameters": {
        "Payload": {
          "SELECTED_RUN_DATE.$": "$.SELECTED_RUN_DATE"
        },
        "FunctionName": "arn:aws:lambda:us-west-2:420393866958:function:run-date-selector-sap-datalakepredevtest3:$LATEST"
      },
      "Retry": [
        {
          "ErrorEquals": [
            "Lambda.ServiceException",
            "Lambda.AWSLambdaException",
            "Lambda.SdkClientException",
            "Lambda.TooManyRequestsException"
          ],
          "IntervalSeconds": 1,
          "MaxAttempts": 3,
          "BackoffRate": 2
        }
      ],
      "ResultPath": "$.run_date_selector",
      "Next": "Set Scope Variable"
    },
    "Set Scope Variable": {
      "Type": "Pass",
      "Result": {
        "SCOPE": "sap_poc-datalake"
      },
      "ResultPath": "$.Param",
      "Next": "Schema Validation Job"
    },
    "Schema Validation Job": {
      "Type": "Task",
      "Resource": "arn:aws:states:::glue:startJobRun.sync",
      "Parameters": {
        "JobName": "validation-schema-check-datalake-frameworkpredevtest3",
        "Arguments": {
          "--CALCULATED_RUN_DATE.$": "$.run_date_selector.Payload.calculated_run_date",
          "--SCOPE.$": "$.Param.SCOPE"
        }
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "Schema Validation job failed",
          "ResultPath": "$.Status",
          "Next": "NotifyFailure"
        }
      ],
      "Next": "Landing to Raw Job",
      "ResultPath": "$.Status"
    },
    "Landing to Raw Job": {
      "Type": "Task",
      "Resource": "arn:aws:states:::glue:startJobRun.sync",
      "Parameters": {
        "JobName": "landing-to-raw-datalake-frameworkpredevtest3",
        "Arguments": {
          "--CALCULATED_RUN_DATE.$": "$.run_date_selector.Payload.calculated_run_date",
          "--SCOPE.$": "$.Param.SCOPE"
        }
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "Landing to Raw layer Job is failed",
          "ResultPath": "$.Status",
          "Next": "NotifyFailure"
        }
      ],
      "ResultPath": "$.Status",
      "Next": "Processed Job"
    },
    "Processed Job": {
      "Type": "Task",
      "Resource": "arn:aws:states:::glue:startJobRun.sync",
      "Parameters": {
        "JobName": "raw-to-processed-datalake-frameworkpredevtest3",
        "Arguments": {
          "--CALCULATED_RUN_DATE.$": "$.run_date_selector.Payload.calculated_run_date",
          "--SCOPE.$": "$.Param.SCOPE"
        }
      },
      "Catch": [
        {
          "ErrorEquals": [
            "States.ALL"
          ],
          "Comment": "Processed job failed",
          "Next": "NotifyFailure",
          "ResultPath": "$.Status"
        }
      ],
      "ResultPath": "$.Status",
      "Next": "NotifySuccess"
    },
    "NotifySuccess": {
      "Type": "Task",
      "Resource": "arn:aws:states:::sns:publish",
      "Parameters": {
        "TopicArn.$": "$.callbackInfo.snsTopicArn",
        "Message": {
          "status": "SUCCESS",
          "executionArn.$": "$$.Execution.Name",
          "completedAt.$": "$$.State.EnteredTime",
          "processedFile": {
            "bucket.$": "$.bucket",
            "key.$": "$.key"
          },
          "callbackInfo.$": "$.callbackInfo"
        }
      },
      "End": true
    },
    "NotifyFailure": {
      "Type": "Task",
      "Resource": "arn:aws:states:::sns:publish",
      "Parameters": {
        "TopicArn.$": "$.callbackInfo.snsTopicArn",
        "Message": {
          "status": "FAILED",
          "executionArn.$": "$$.Execution.Name",
          "failedAt.$": "$$.State.EnteredTime",
          "error.$": "$.Status",
          "processedFile": {
            "bucket.$": "$.bucket",
            "key.$": "$.key"
          },
          "callbackInfo.$": "$.callbackInfo"
        }
      },
      "Next": "Fail"
    },
    "Fail": {
      "Type": "Fail"
    }
  }
}
