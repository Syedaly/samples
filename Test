# SAP BW to AWS Migration: Source-to-Target Mapping 

  

## **Context & Architecture Requirements** 

**Context** : I am working on a SAP BW to AWS migration project. We have metadata of SAP Process Chain. You must analyze the process chain document 

as per the below requirements. 

  

**Architecture** 

- Ingestion: Qlik Replicate (SAP→S3 Parquet) 

- Processing: AWS Glue ETL   

- Storage: S3 Medallion + Redshift Serverless 

  

**Medallion Jobs:** 

1. Landing→Raw: "landing-to-raw-[chain-name]" 

2. Raw→Processed: "raw-to-processed-[chain-name]" 

3. Processed→Analytics: Individual per target table 

  

## Task: Generate Source-to-Target Mapping from SAP Process Chain Document 

  

Step 1: Extract ALL TARGET TRANSFORMATIONS from RSPC_OUTPUT sheet 

- Identify EVERY row where STEP_TYPE = "DTP_LOAD"  

- Extract ALL unique combinations of (STEP_ID, TARGET_NAME) as separate transformations 

- Do NOT filter or prioritize - each combination represents a distinct ETL job requirement 

- Expected result: Complete list of all transformation targets, not just "final" ones 

  

Example format: 

STEP_ID_1 → TARGET_A 

STEP_ID_2 → TARGET_A  (different transformation to same target) 

STEP_ID_3 → TARGET_B 

  

**Step 2:** For each (STEP_ID, TARGET_NAME) combination, create direct source-to-target mappings by: 

  

- Within EACH individual STEP_ID: Skip intermediate staging tables and map directly from original source to final target 

- ACROSS different STEP_IDs: Treat each as a separate transformation (do not skip) 

- Rule: If STEP_ID_X has Source_A → Intermediate_B → Target_C, then map Source_A → Target_C 

- Rule: If STEP_ID_Y also targets Target_C, create a separate mapping for STEP_ID_Y 

  

  

Example: 

- STEP_ID_1: 0BP_ATTR → ZBP_INTERMEDIATE → 0UCIODS08 = Map 0BP_ATTR → 0UCIODS08 

- STEP_ID_2: 0CREDIT → 0UCIODS08 = Separate mapping 0CREDIT → 0UCIODS08 

  

**Step 3: Analyze Data Transformation Logic from Source Table to Target Table** 

From **TRFN_HEADER_OUTPUT** sheet: 

For each combination of TARGET_NAME & STEP_ID: 

- Extract START_ROUTINE_PART1/2 

- Analyze START_ROUTINE_PART1/2 

From **TRFN_DETAILS_OUTPUT** sheet: 

For each combination of TARGET_NAME & STEP_ID: 

- Map SOURCE_COL → TARGET_COL relationships 

- Extract FIELD_ROUTINE_PART1 & FIELD_ROUTINE_PART2 (ABAP transformation code) 

- Group by STEP_ID for each target table 

### **Step 3: Generate Mapping Table** 

  

Create a pipe-delimited table with these exact columns: 

  

**Header:** 

``` 

SAP Process Chain Step ID|Database Name|Target Table Name|Target Column Name|Target Column Description|Key Flag|Column Order|Target Column Data Type|Transformation Rule|SAP Transformation Routine|Target Data Conversion|ABAP Code Conversion Confidence|Source Database Name|Source Table Name|Source Column Name|Source Column Data Type|Source Column Description|Comment 

``` 

For each combination of TARGET_NAME & STEP_ID: 

  

**Column Population Rules:** 

- **SAP Process Chain Step ID** : From STEP_ID  

- **Database Name**: "analytics_customer_db" 

- **Target Table Name**: From FINAL_TARGETS 

- **Target Column Name**: TARGET_COL from TRFN_DETAILS_OUTPUT sheet 

- **Target Column Description**: TG_COL_DESC from TRFN_DETAILS_OUTPUT 

- **Key Flag**: T_KEYFLAG from TRFN_DETAILS_OUTPUT 

- **Column Order**: Key columns (T_KEYFLAG="X") first, then others 

- **Target Column Data Type**: Convert using mapping below + precision from TAR_LENG/TAR_DECIMALS 

  

**SAP to AWS Iceberg Data Type Mapping:** 

``` 

ACCP → date          CHAR → string        CLNT → integer 

CUKY → string        CURR → decimal       DATS → date 

DEC → decimal        FLTP → float         INT1/2/4 → integer 

LANG → string        LCHR → string        NUMC → string 

QUAN → decimal       RAW → string         SSTR → string 

STRG → string        TIMS → timestamp     UNIT → string 

``` 

  

- **Transformation Rule**: Convert FIELD_ROUTINE_PART1/2 + START_ROUTINE_PART1 to **SQL Format Only** 

** ZZBW_CLEANTEXT**: Read this as text cleaning function similar to SQL syntax example --> REGEXP_REPLACE(REGEXP_REPLACE(COLUMN_NAME, '[\t\n\r]', ' '), '[^A-Za-z0-9 ]', '') 

** Use SQL function to interpret ABAP Code conversion to SQL  

** Use CASE, IF ELSE syntax for applicable scenarios  

** Use other SQL functions like UPPER, LOWER, LTRIM,RTRIM, TRIM,INITCAP, SUBSTRING, LEFT, RIGHT, CONCAT, COMCAT_WS, REPLACE , REVERSE etc. 

** For Lookup : Example LOOKUP <LOOKUP_TABLE> JOIN ON SOURCE.COLUMN_NAME = LOOKUP_TABLE.COLUMN_NAME GET LOOKUP_TABLE.COLUMN_NAME || LOOKUP_TABLE.COLUMN_NAME 

** For Direct Transformation --> Mention **Direct Transformation** 

** If **TAR_CONVEXIT** is available, convert this in SQL as a transformation rule. 

Example : **ALPHA**  --> LPAD(LTRIM(RTRIM(COLUMN_NAME)), 4, '0') where '4' is the length of the target column 

- **SAP Transformation Routine**: **FIELD_ROUTINE_PART1** from **TRFN_DETAILS_OUTPUT**. **ABAP Code Only** 

- **Target Data Conversion**: **TAR_CONVEXIT** from **TRFN_DETAILS_OUTPUT**. **DON'T MODIFY** 

- **ABAP Code Conversion Confidence**:  

  - High: Successfully converted to **SQL** 

  - Medium: Partially understood 

  - Low: Requires manual intervention 

- **Source Database Name**: "sap_processed_db" 

- **Source Table Name**: SOURCE_NAME from TRFN_DETAILS_OUTPUT 

- **Source Column Name**: SOURCE_COL from TRFN_DETAILS_OUTPUT 

- **Source Column Data Type**: Convert SRC_DATATYPE using same mapping + SRC_LENG/SRC_DECIMALS 

- **Source Column Description**: SR_COL_DESC from TRFN_DETAILS_OUTPUT 

- **Comment**: Include data truncation notes, ALPHA conversions, developer guidance 

**COMPLETENESS REQUIREMENT:** 

- Extract EVERY row from TRFN_DETAILS_OUTPUT for each STEP_ID 

- DO NOT provide samples results 

- If a STEP_ID has 105 column *UNIQUE* target column, provide all 105 unique target column with corresponding source mapping 

- Missing columns will result in incomplete ETL specification 

  

**DEDUPLICATION REQUIREMENT:** 

- Identify ALL duplicate TARGET_COL names within each STEP_ID 

- For duplicate targets, consolidate into ONE unique target column entry 

- Combine transformation logic using CASE statements or any other appropriate SQL functions 

- Comments: List all consolidated sources as "Consolidates: SOURCE1(type1), SOURCE2(type2)..." 

- Example: If TARGET_COL "FISCYEAR" appears 4 times with different sources, create ONE "FISCYEAR" entry with consolidated logic  

- Merge all FIELD_ROUTINE_PART1 variations into single comprehensive routine 

  

**IMPORTANT: Multiple STEP_IDs can target the same table 

- Each represents a different data source/transformation path 

- Each requires separate mapping entries   

- Do NOT consolidate - they represent different ETL jobs 

- Example: If 3 STEP_IDs target 0UCIODS08, generate 3 separate mapping sections 

  

**Pre-Submission Checklist:** 

- **Transformation Rule** is populated in equivalent SQL if FIELD_ROUTINE_PART1/2 OR TAR_CONVEXIT values are available 

- Ensure each combination of (STEP_ID, TARGET_NAME) are available 

- Ensure all the distinct TARGET_COL for each TARGET_NAME table are present 

- FIELD_ROUTINE_PART1/2 values extracted for all applicable fields and populate **SAP Transformation Routine** 

- TAR_CONVEXIT values extracted for all applicable fields and populate **Target Data Conversion** 

  

  

**Error Handling:** 

- For complex ABAP: Set confidence to "Medium/Low" and explain in Comment field 

- For missing data: Note in Comment field for manual review 

  

--- 

  

**Expected Output:** Complete source-to-target mapping table ready for AWS Glue ETL job development **ORDER BY TARGET_NAME , STEP_ID **. 

  

--- 
